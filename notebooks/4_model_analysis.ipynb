{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f160de27",
   "metadata": {},
   "source": [
    "# 4_model_analysis.ipynb\n",
    "\n",
    "- **Objectif** :\n",
    "Analyser les mod√®les enregistr√©s dans MLflow,\n",
    "comparer leurs performances et visualiser les m√©triques cl√©s.\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c944aae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, roc_curve, auc\n",
    "from joblib import load"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84486e31",
   "metadata": {},
   "source": [
    "\n",
    "# 1Ô∏è‚É£ R√©cup√©ration des runs MLflow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b21c002",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.set_tracking_uri(\"file:./mlruns\")\n",
    "experiment_name = \"Churn_Prediction_Models\"\n",
    "client = mlflow.tracking.MlflowClient()\n",
    "experiment = client.get_experiment_by_name(experiment_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "732b4fa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "if experiment is None:\n",
    "    raise ValueError(f\"‚ö†Ô∏è Aucun experiment MLflow trouv√© avec le nom : {experiment_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a10075e",
   "metadata": {},
   "outputs": [],
   "source": [
    "runs = mlflow.search_runs(experiment_ids=[experiment.experiment_id])\n",
    "print(f\"‚úÖ {len(runs)} runs trouv√©s pour l'exp√©rience '{experiment_name}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7939974f",
   "metadata": {},
   "source": [
    "# 2Ô∏è‚É£ Synth√®se des performances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8455212",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================================\n",
    "# 2Ô∏è‚É£ Synth√®se des performances\n",
    "# ==========================================================\n",
    "metrics_summary = runs[[\"tags.model_name\", \"tags.imbalance_strategy\",\n",
    "                        \"metrics.f1_score\", \"metrics.accuracy\", \"run_id\"]].sort_values(\"metrics.f1_score\", ascending=False)\n",
    "metrics_summary.columns = [\"Model\", \"Strategy\", \"F1_score\", \"Accuracy\", \"Run_ID\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "655a04a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(metrics_summary.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ebd2e77",
   "metadata": {},
   "source": [
    "# 3Ô∏è‚É£ Visualisation compar√©e (F1 & Accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51cedbca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================================\n",
    "# 3Ô∏è‚É£ Visualisation compar√©e (F1 & Accuracy)\n",
    "# ==========================================================\n",
    "plt.figure(figsize=(8,5))\n",
    "sns.barplot(data=metrics_summary, x=\"Model\", y=\"F1_score\", hue=\"Strategy\")\n",
    "plt.title(\"üìä Comparaison du F1-score par mod√®le et strat√©gie\")\n",
    "plt.ylabel(\"F1-score\")\n",
    "plt.legend(title=\"Strat√©gie\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79e40869",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,5))\n",
    "sns.barplot(data=metrics_summary, x=\"Model\", y=\"Accuracy\", hue=\"Strategy\")\n",
    "plt.title(\"üìà Comparaison de l‚ÄôAccuracy par mod√®le et strat√©gie\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend(title=\"Strat√©gie\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d64d14b1",
   "metadata": {},
   "source": [
    "# 4Ô∏è‚É£ S√©lection du meilleur mod√®le"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c4560e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================================\n",
    "# 4Ô∏è‚É£ S√©lection du meilleur mod√®le\n",
    "# ==========================================================\n",
    "best_run = metrics_summary.iloc[0]\n",
    "print(f\"üèÜ Meilleur mod√®le : {best_run['Model']} ({best_run['Strategy']})\")\n",
    "print(f\"F1 = {best_run['F1_score']:.3f} | Accuracy = {best_run['Accuracy']:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e05282a2",
   "metadata": {},
   "source": [
    "## Charger le mod√®le depuis MLflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a5650c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Charger le mod√®le depuis MLflow\n",
    "model_uri = f\"runs:/{best_run['Run_ID']}/model\"\n",
    "best_model = mlflow.sklearn.load_model(model_uri)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa8b0426",
   "metadata": {},
   "source": [
    "## Charger les donn√©es test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5def0dc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Charger les donn√©es test\n",
    "X_test = load(\"data/X_test.pkl\")\n",
    "y_test = load(\"data/y_test.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b118791",
   "metadata": {},
   "source": [
    "# 5Ô∏è‚É£ Visualisations de performance du meilleur mod√®le"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e336a62f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================================\n",
    "# 5Ô∏è‚É£ Visualisations de performance du meilleur mod√®le\n",
    "# ==========================================================\n",
    "y_pred = best_model.predict(X_test)\n",
    "y_proba = best_model.predict_proba(X_test)[:,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cea9b829",
   "metadata": {},
   "source": [
    "## Matrice de confusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70a4c1bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matrice de confusion\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "ConfusionMatrixDisplay(cm).plot(cmap=\"Blues\")\n",
    "plt.title(f\"Confusion Matrix - {best_run['Model']} ({best_run['Strategy']})\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc420cee",
   "metadata": {},
   "source": [
    "## Courbe ROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "482c0a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Courbe ROC\n",
    "fpr, tpr, _ = roc_curve(y_test, y_proba)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "plt.figure(figsize=(6,6))\n",
    "plt.plot(fpr, tpr, label=f\"AUC = {roc_auc:.3f}\")\n",
    "plt.plot([0,1], [0,1], linestyle=\"--\", color=\"gray\")\n",
    "plt.title(f\"ROC Curve - {best_run['Model']} ({best_run['Strategy']})\")\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9a57c77",
   "metadata": {},
   "source": [
    "# 6Ô∏è‚É£ Export de la synth√®se"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "891ff05c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================================\n",
    "# 6Ô∏è‚É£ Export de la synth√®se\n",
    "# ==========================================================\n",
    "metrics_summary.to_csv(\"reports/model_comparison_results.csv\", index=False)\n",
    "print(\"üíæ R√©sultats sauvegard√©s dans reports/model_comparison_results.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be2fce5a",
   "metadata": {},
   "source": [
    "# 7Ô∏è‚É£ Rapport rapide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "588957b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================================\n",
    "# 7Ô∏è‚É£ Rapport rapide\n",
    "# ==========================================================\n",
    "import markdown\n",
    "summary_text = f\"\"\"\n",
    "# üßæ Rapport de comparaison des mod√®les\n",
    "\n",
    "**Exp√©rience MLflow :** {experiment_name}\n",
    "\n",
    "**Nombre de runs :** {len(runs)}\n",
    "\n",
    "**Meilleur mod√®le :** {best_run['Model']} ({best_run['Strategy']})\n",
    "- F1-score : {best_run['F1_score']:.3f}\n",
    "- Accuracy : {best_run['Accuracy']:.3f}\n",
    "\n",
    "Les figures ci-dessus montrent la comparaison entre les trois mod√®les et les diff√©rentes strat√©gies d'√©quilibrage.\n",
    "Le meilleur compromis entre pr√©cision et rappel est obtenu avec **{best_run['Model']}** en mode **{best_run['Strategy']}**.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1468eab",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"reports/model_comparison.md\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(summary_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bba8a1a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üìò Rapport enregistr√© : reports/model_comparison.md\")"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
